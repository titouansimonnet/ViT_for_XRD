{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d874c047",
   "metadata": {},
   "source": [
    "# ViT for mineral phases quantification from XRD patterns  \n",
    "A 4 classes problem, i.e 4 mineral phases: Calcite, Dolomite, Gibbsite and Hematite  \n",
    "Quantify each mineral phase from an XRD pattern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b56d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from netrc import netrc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU, GRU\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a05f1",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a1cc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"Number of available GPUs:\", torch.cuda.device_count())\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8af44a9",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6f457ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclasses = ['Calcite','Gibbsite','Dolomite','Hematite']\\npath = 'Databases/Proportion'\\n\\nclass Diffractogramm(Dataset):\\n    def __init__(self, train = 'train'):\\n        self.train = train\\n        if (self.train == 'train'):\\n            self.data_prob = torch.tensor(pd.read_csv(path+'label_train.txt',sep = ',').values).to(device)\\n            self.data_file = torch.tensor(pd.read_csv(path+'Data_train.txt', sep = ',', header = None).values).to(device)\\n        if (self.train == 'val'):\\n            self.data_prob = torch.tensor(pd.read_csv(path+'label_val.txt',sep=',').values).to(device)\\n            self.data_file = torch.tensor(pd.read_csv(path+'Data_val.txt', sep = ',', header = None).values).to(device)\\n\\n        \\n    def __len__(self):\\n        return self.data_prob.shape[0]\\n\\n    def __getitem__(self, idx):\\n        I = self.data_file[idx,:]\\n        prop = self.data_prob[idx,:]\\n        I = I.float()\\n        sample = [I,prop]\\n        return sample\\n        \\n#Create the datasets/dataloader (train & validation)\\nbatch_size_train = 128\\nbatch_size_val = 128\\ntrainset = Diffractogramm(train = 'train')\\nvalset = Diffractogramm(train = 'val')\\ndataloader = DataLoader(trainset, batch_size = batch_size_train, shuffle = True, num_workers=0)\\nvalidloader = DataLoader(valset, batch_size = batch_size_val , shuffle = True, num_workers=0)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "classes = ['Calcite','Gibbsite','Dolomite','Hematite']\n",
    "path = 'Databases/Proportion'\n",
    "\n",
    "class Diffractogramm(Dataset):\n",
    "    def __init__(self, train = 'train'):\n",
    "        self.train = train\n",
    "        if (self.train == 'train'):\n",
    "            self.data_prob = torch.tensor(pd.read_csv(path+'label_train.txt',sep = ',').values).to(device)\n",
    "            self.data_file = torch.tensor(pd.read_csv(path+'Data_train.txt', sep = ',', header = None).values).to(device)\n",
    "        if (self.train == 'val'):\n",
    "            self.data_prob = torch.tensor(pd.read_csv(path+'label_val.txt',sep=',').values).to(device)\n",
    "            self.data_file = torch.tensor(pd.read_csv(path+'Data_val.txt', sep = ',', header = None).values).to(device)\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_prob.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        I = self.data_file[idx,:]\n",
    "        prop = self.data_prob[idx,:]\n",
    "        I = I.float()\n",
    "        sample = [I,prop]\n",
    "        return sample\n",
    "        \n",
    "#Create the datasets/dataloader (train & validation)\n",
    "batch_size_train = 128\n",
    "batch_size_val = 128\n",
    "trainset = Diffractogramm(train = 'train')\n",
    "valset = Diffractogramm(train = 'val')\n",
    "dataloader = DataLoader(trainset, batch_size = batch_size_train, shuffle = True, num_workers=0)\n",
    "validloader = DataLoader(valset, batch_size = batch_size_val , shuffle = True, num_workers=0)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b41b1fb",
   "metadata": {},
   "source": [
    "## ViT block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f29110",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" *** FUNCTIONS*** \"\"\"\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim,\n",
    "                 num_heads,\n",
    "                 mlp_ratio=4.,\n",
    "                 qkv_bias=False,\n",
    "                 qk_scale=None,\n",
    "                 drop_ratio=0.,\n",
    "                 attn_drop_ratio=0.,\n",
    "                 drop_path_ratio=0.,\n",
    "                 act_layer=nn.GELU,\n",
    "                 norm_layer=nn.LayerNorm):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = Attention(dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                              attn_drop_ratio=attn_drop_ratio, proj_drop_ratio=drop_ratio)\n",
    "        self.drop_path = DropPath(\n",
    "            drop_path_ratio) if drop_path_ratio > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim,\n",
    "                       act_layer=act_layer, drop=drop_ratio)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 dim,\n",
    "                 num_heads=2,\n",
    "                 qkv_bias=False,\n",
    "                 qk_scale=None,\n",
    "                 attn_drop_ratio=0.,\n",
    "                 proj_drop_ratio=0.):\n",
    "        super(Attention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop_ratio)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop_ratio)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # [batch_size, num_patches + 1, total_embed_dim]\n",
    "        B, N, C = x.shape\n",
    "        # qkv(): -> [batch_size, num_patches + 1, 3 * total_embed_dim]\n",
    "        # reshape: -> [batch_size, num_patches + 1, 3, num_heads, embed_dim_per_head]\n",
    "        # permute: -> [3, batch_size, num_heads, num_patches + 1, embed_dim_per_head]\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        # [batch_size, num_heads, num_patches + 1, embed_dim_per_head]\n",
    "        # make torchscript happy (cannot use tensor as tuple)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        # transpose: -> [batch_size, num_heads, embed_dim_per_head, num_patches + 1]\n",
    "        # @: multiply -> [batch_size, num_heads, num_patches + 1, num_patches + 1]\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        # @: multiply -> [batch_size, num_heads, num_patches + 1, embed_dim_per_head]\n",
    "        # transpose: -> [batch_size, num_patches + 1, num_heads, embed_dim_per_head]\n",
    "        # reshape: -> [batch_size, num_patches + 1, total_embed_dim]\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "\n",
    "def Spectra_Embedding(x, spec_length, embed_dim):\n",
    "    batch_size = x.shape[0]\n",
    "    new_spec_length = (spec_length // embed_dim) * embed_dim\n",
    "    x = x[:, :new_spec_length]\n",
    "    x = torch.reshape(x, (batch_size, spec_length // embed_dim, embed_dim))\n",
    "    return x\n",
    "\n",
    "        \n",
    "class VIT(nn.Module):\n",
    "    def __init__(self, spec_length=2000, num_output=1,\n",
    "                 embed_dim=40, depth=12, num_heads=2, mlp_ratio=4.0, qkv_bias=True,\n",
    "                 qk_scale=None, drop_ratio=0.,\n",
    "                 attn_drop_ratio=0., drop_path_ratio=0., norm_layer=None,\n",
    "                 act_layer=None):\n",
    "        \n",
    "        # MSTransformer\n",
    "        super(VIT, self).__init__()\n",
    "        self.num_classes = num_output\n",
    "        self.spec_length = spec_length\n",
    "        self.num_features = self.embed_dim = embed_dim\n",
    "        norm_layer = norm_layer or partial(nn.LayerNorm, eps=1e-6)\n",
    "        act_layer = act_layer or nn.GELU\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, (spec_length//embed_dim) + 1, embed_dim))\n",
    "        self.pos_drop = nn.Dropout(p=drop_ratio)\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_ratio, depth)]\n",
    "        self.blocks = nn.Sequential(*[\n",
    "            EncoderBlock(dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                        drop_ratio=drop_ratio, attn_drop_ratio=attn_drop_ratio, drop_path_ratio=dpr[i],\n",
    "                        norm_layer=norm_layer, act_layer=act_layer)\n",
    "            for i in range(depth)\n",
    "        ])\n",
    "        self.norm = norm_layer(embed_dim)\n",
    "        \n",
    "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
    "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
    "        self.apply(_init_vit_weights)\n",
    "\n",
    "        self.head = nn.Linear(embed_dim, num_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # [B , xrd_length] --> [B , xrd_length/embed_dim , embed_dim]\n",
    "        x = Spectra_Embedding(x, self.spec_length, self.embed_dim)\n",
    "        cls_token = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_token, x), dim=1)\n",
    "        x = self.pos_drop(x + self.pos_embed)\n",
    "        x = self.blocks(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x[:, 0]\n",
    "    \n",
    "def _init_vit_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.trunc_normal_(m.weight, std=.01)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.LayerNorm):\n",
    "        nn.init.zeros_(m.bias)\n",
    "        nn.init.ones_(m.weight)\n",
    "\n",
    "def VIT_model(spec_length=2905,num_output: int = 1):\n",
    "    model = VIT(spec_length=spec_length,\n",
    "                              embed_dim=80,\n",
    "                              depth=12,\n",
    "                              num_heads=2,\n",
    "                              num_output=num_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f170b5ed",
   "metadata": {},
   "source": [
    "## Loss function: MSE & Dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd0cdcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Definition of a class (nn.Module) for the 5 loss function :\n",
    "    - forward method is used during the training (loss function)\n",
    "    - prediction method is used for validation and test set like a predictor\n",
    "\n",
    "*** PARAMETERS *** (for each function)\n",
    "    - a is the output of the neural network\n",
    "    - p is the proportion vector from the ground truth\n",
    "\"\"\"\n",
    "\n",
    "#Loss 1 : DIR & MSE\n",
    "class LossDirichlet_MSE(nn.Module):\n",
    "    def forward(self, a , p):\n",
    "        b,K = a.shape # batch size and number of classes\n",
    "        alpha = F.relu(a) + 1.0 #phi function of the paper\n",
    "        S = torch.sum(alpha, dim = 1, keepdim = True) # sum of alpha\n",
    "        moment_1 = alpha / S #moment of order 1 for Dirichlet Distribution\n",
    "        moment_2 = alpha*(1+alpha) / (S*(1+S)) #moment of order 2 for Dirichlet Distribution\n",
    "        L = torch.sum((p*p - 2*p*moment_1 + moment_2), dim = 1)\n",
    "        L = torch.mean(L)\n",
    "        return(L)\n",
    "    \n",
    "    def prediction(self,a):\n",
    "        output = F.relu(a) + 1.0\n",
    "        S = torch.sum(output,dim = 1, keepdim = True)\n",
    "        output = output/S\n",
    "        return(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742ed031",
   "metadata": {},
   "source": [
    "## Train function \n",
    "\n",
    "Use of Tensorboard  \n",
    "Return the trained model, epoch with the best MMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc97089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, nb_epoch, criterion, eps, N_train, num_classes):\n",
    "    writer = SummaryWriter(log_dir = 'Tensorboard')\n",
    "    norm_val = np.inf\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(),lr = 0.0001)\n",
    "    n_train = len(trainset)\n",
    "    iter_info = 100\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(nb_epoch):\n",
    "        since_epoch = time.time()\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0\n",
    "        model.train()\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            images = data[0]\n",
    "            proportion = data[1]\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs.float(),proportion.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item() * batch_size_train\n",
    "            if i % iter_info == (iter_info-1):    # print every iter_info mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                (epoch + 1, i + 1, running_loss / iter_info))\n",
    "                running_loss = 0.0\n",
    "        time_elapsed_epoch = time.time() - since_epoch\n",
    "        print('Epoch completed in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed_epoch // 60, time_elapsed_epoch % 60))\n",
    "        epoch_loss = epoch_loss / n_train\n",
    "        print('Epoch loss: %.3f' % (epoch_loss))\n",
    "        writer.add_scalar('Epoch_loss/train', epoch_loss, epoch)\n",
    "\n",
    "        #Validation set\n",
    "        norme_inf = 0\n",
    "        norme_2 = 0\n",
    "        good_support = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for data in validloader:\n",
    "                images = data[0]\n",
    "                p = data[1]\n",
    "                output = model(images)\n",
    "                output = criterion.prediction(output)\n",
    "                \n",
    "                predictive_support = output > eps\n",
    "                true_support = (p > 0)\n",
    "                for m in range(predictive_support.shape[0]):\n",
    "                    if torch.equal(true_support[m],predictive_support[m]):\n",
    "                        good_support = good_support + 1\n",
    "                \n",
    "                Diff_abs = torch.abs(p-output)\n",
    "                norme_inf = norme_inf + torch.sum(torch.amax(Diff_abs,axis = 1))\n",
    "                norm = (p-output)**2\n",
    "                norme_2 = norme_2 + torch.sum(torch.mean(norm,axis = 1))\n",
    "\n",
    "            norme_inf = norme_inf / len(valset)\n",
    "            norme_2 = norme_2 / len(valset)\n",
    "            RMSE = torch.sqrt(norme_2)\n",
    "            supp = good_support/len(valset)\n",
    "            \n",
    "            writer.add_scalar('MMAE',norme_inf,epoch)\n",
    "            writer.add_scalar('RRS', supp,epoch)\n",
    "            writer.add_scalar('RMSE',RMSE,epoch)\n",
    "            \n",
    "            print(str(criterion))\n",
    "            print('Epoch: ',epoch+1,', MMAE : ', norme_inf)\n",
    "            print('RMSE : ',RMSE)\n",
    "            print('RRS : ',supp)\n",
    "            \n",
    "            if (norme_inf < norm_val):\n",
    "                norm_val = norme_inf\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print('Model epoch is better')\n",
    "                    \n",
    "    print('Finished Training')\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training completed in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return(model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af58814",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab085d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnb_epoch = 1000\\neps = 1e-2\\nnum_classes=4\\nnb_train = 5\\nfor w in range(nb_train):    \\n    model = VIT_model(spec_length=2905,num_output=num_classes)\\n    model = model.to(device)\\n    criterion = LossDirichlet_MSE()\\n    print('Train '+ str(w) +' :Dirichlet & MSE')\\n    model_train = train(model = model, nb_epoch = nb_epoch, criterion = criterion, eps = eps, N_train = w, num_classes = num_classes)\\n    torch.save(model_train.state_dict(),f = 'Trained_model')\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "nb_epoch = 1000\n",
    "eps = 1e-2\n",
    "num_classes=4\n",
    "nb_train = 5\n",
    "for w in range(nb_train):    \n",
    "    model = VIT_model(spec_length=2905,num_output=num_classes)\n",
    "    model = model.to(device)\n",
    "    criterion = LossDirichlet_MSE()\n",
    "    print('Train '+ str(w) +' :Dirichlet & MSE')\n",
    "    model_train = train(model = model, nb_epoch = nb_epoch, criterion = criterion, eps = eps, N_train = w, num_classes = num_classes)\n",
    "    torch.save(model_train.state_dict(),f = 'Trained_model')\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba9ecd1",
   "metadata": {},
   "source": [
    "## Test the trained model on 32 real data\n",
    "\n",
    "### Load the real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24ea3566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2905])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "***Classes definition and path to data***\n",
    "\"\"\"\n",
    "classes = ['Calcite','Gibbsite','Dolomite','Hematite']\n",
    "path = 'Databases/Real_data/'\n",
    "\n",
    "real_datalist = pd.read_csv(path+'Labels_T.csv', sep=';',header=None,names=['file','Calcite','Gibbsite',\n",
    "                                        'Dolomite','Hematite'],skiprows=1)\n",
    "\n",
    "Data = torch.zeros(32,2905)\n",
    "for i in range(32):\n",
    "    V = pd.read_csv(path+real_datalist['file'][i],header = None, skiprows = 0,\n",
    "                    names = ['angle','intensity'],sep = ',')\n",
    "    V_tensor = np.asarray(V['intensity'])\n",
    "    V_tensor = torch.tensor(V_tensor).float()\n",
    "    if (len(V_tensor) == 2905):\n",
    "        Data[i,:] = V_tensor\n",
    "        \n",
    "        \n",
    " \n",
    "\"\"\"\n",
    "Data pre-processing\n",
    "\"\"\"\n",
    "Data_m_2 = np.array(Data)\n",
    "for i in range(len(Data_m_2)):\n",
    "    m = min(Data_m_2[i,:])\n",
    "    Data_m_2[i,:] = Data_m_2[i,:] - m\n",
    "    Data_m_2[i,:] = Data_m_2[i,:]/max(Data_m_2[i,:])\n",
    "Data_M_2 = torch.tensor(Data_m_2)\n",
    "print(Data_M_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a8f9d7",
   "metadata": {},
   "source": [
    "### Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21f548a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to test the trained neural network on the pixels of the Data\n",
    "*** PARAMETERS ***\n",
    "- model = trained neural network\n",
    "- output_file = file for write the output (RMSE, Infinite norm, %Support)\n",
    "- criterion : criterion use for trained NN (use \"out\" method)\n",
    "\"\"\"\n",
    "\n",
    "def test (model, criterion):\n",
    "    model_ft = model\n",
    "    norme_inf = 0\n",
    "    norme_2 = 0\n",
    "    norme_2_classes = np.zeros(len(classes))\n",
    "    good_support = 0\n",
    "    eps = 7e-2\n",
    "    with torch.no_grad():\n",
    "        model_ft.eval()\n",
    "        for i in range(len(Data_M_2)):\n",
    "            #Load the data\n",
    "            images = Data_M_2[i,:]\n",
    "            images = torch.unsqueeze(images,0)\n",
    "            \n",
    "            #Load the label\n",
    "            prop_Calcite = real_datalist.loc[i,'Calcite']\n",
    "            prop_Gibbsite = real_datalist.loc[i,'Gibbsite']\n",
    "            prop_Dolomite = real_datalist.loc[i,'Dolomite']\n",
    "            prop_Hematite = real_datalist.loc[i,'Hematite']\n",
    "            p = torch.tensor([prop_Calcite,prop_Gibbsite,prop_Dolomite,prop_Hematite])\n",
    "            \n",
    "            #Results after NN\n",
    "            y = model_ft(images)\n",
    "            res = criterion.prediction(y)\n",
    "            res = res.squeeze(0)\n",
    "            #print(res)\n",
    "            \n",
    "            #Support\n",
    "            predictive_support = res > eps\n",
    "            true_support = (p > 0)\n",
    "            if np.array_equal(true_support,predictive_support):\n",
    "                good_support = good_support + 1\n",
    "            \n",
    "            #MMAE\n",
    "            Diff_abs = torch.abs(p - res)\n",
    "            Diff_abs = np.array(Diff_abs)\n",
    "            norme_inf = norme_inf + np.amax(Diff_abs)\n",
    "            \n",
    "            #RMSE\n",
    "            norm = np.array((p-res)**2)\n",
    "            norme_2 = norme_2 + np.mean(norm)\n",
    "            norme_2_classes = norme_2_classes + norm\n",
    "            \n",
    "        MMAE = norme_inf / len(Data)\n",
    "        norme_2 = norme_2 / len(Data)\n",
    "        RMSE = np.sqrt(norme_2)\n",
    "        RMSE_classes = np.sqrt( norme_2_classes / len(Data))\n",
    "        \n",
    "        supp = good_support / len(Data)\n",
    "\n",
    "        \n",
    "    \n",
    "        return (MMAE, RMSE, supp, RMSE_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce9c6097",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(classes)\n",
    "model_ft = VIT_model(spec_length=2905,num_output=num_classes)\n",
    "criterion = LossDirichlet_MSE()\n",
    "model_ft.load_state_dict(torch.load('Trained_model/Prop' ,map_location=torch.device('cpu')))\n",
    "MMAE, RMSE, Supp, RMSE_classes = test(model = model_ft, criterion = criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c089d9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMAE:  0.05810671030944077\n",
      "RMSE:  0.04561921506860975\n",
      "RRS:  0.96875\n"
     ]
    }
   ],
   "source": [
    "print('MMAE: ', MMAE)\n",
    "print('RMSE: ', RMSE)\n",
    "print('RRS: ', Supp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
